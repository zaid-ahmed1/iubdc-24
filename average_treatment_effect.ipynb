{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalml.dataset import synthetic_data\n",
    "from causalml.inference.meta import BaseXRegressor, BaseRRegressor, LRSRegressor, BaseDRLearner, MLPTRegressor, BaseRLearner, BaseSRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Read in Ace data\n",
    "ace_data = pd.read_csv('ace_data.csv')\n",
    "\n",
    "# y, X, treatment, _, _, e = synthetic_data(mode=1, n=1000, p=5, sigma=1.0)\n",
    "\n",
    "# # Print the shape of the data\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "# print(treatment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['FINALWT', 'GENHLTH', 'MARITAL', '_SEX', 'MENTHLTH', '_EDUCAG',\n",
      "       '_INCOMG1', 'POORHLTH', 'ADDEPEV3', '_AGEG5YR', '_AGE65YR', '_AGE80',\n",
      "       '_AGE_G', 'DECIDE', 'DIFFALON', 'ACEDEPRS', 'ACEDRINK', 'ACEDRUGS',\n",
      "       'ACEPRISN', 'ACEDIVRC', 'ACEPUNCH', 'ACEHURT1', 'ACESWEAR', 'ACETOUCH',\n",
      "       'ACETTHEM', 'ACEHVSEX'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Get the column names of ace_data\n",
    "column_names = ace_data.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the list of treatments with multiple levels\n",
    "multi_levels = ['ACEPUNCH', 'ACEHURT1', 'ACESWEAR', 'ACETOUCH', 'ACETTHEM', 'ACEHVSEX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_analysis(data, target_col, treatment_col, feature_cols, sample_weights_col = 'FINALWT'):\n",
    "\n",
    "    # Drop NAs in the treatment and target columns\n",
    "    data = data.dropna(subset=[treatment_col, target_col])\n",
    "    \n",
    "    # Filter out unwanted responses depending on the treatment\n",
    "    if treatment_col == 'ACEDIVRC':\n",
    "        # Create a dictionary mapping the recoded treatment levels to their original labels\n",
    "        treatment_labels = {0: 'Yes', 1: 'No', 2: 'Parents not married'}\n",
    "\n",
    "        # Keep only the responses that are 1, 2, or 8 (1 = Yes, 2 = No, 8 = Not Married)\n",
    "        data = data[data[treatment_col].isin([1, 2, 8])]\n",
    "        # Recode the treatment variables\n",
    "        data[treatment_col] = data[treatment_col].map({1: 1, 2: 0, 8: 2})\n",
    "        \n",
    "        # Print the control group\n",
    "        print('Control Group is {} i.e. Parents Married'.format(treatment_labels[0]))\n",
    "        \n",
    "        # Declare the treatment and target\n",
    "        treatment = data[treatment_col]\n",
    "        y = data[target_col]\n",
    "\n",
    "        # Declare X\n",
    "        X = data[feature_cols]\n",
    "        \n",
    "        # Declare the sample weights\n",
    "        sample_weights = data[sample_weights_col]\n",
    "        \n",
    "        # Perform the analysis\n",
    "        \n",
    "        # Estimate the ATE using the LRS Regressor\n",
    "        learner_s = LRSRegressor()\n",
    "        te, lb, ub = learner_s.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "        # Print all the treatment average effects\n",
    "        for treatment_level in range(len(te)):\n",
    "            print('ATE with LRS Regressor on treatment {}: {:.2f} ({:.2f}, {:.2f})'\\\n",
    "                .format(treatment_labels[treatment_level + 1], te[treatment_level], lb[treatment_level], ub[treatment_level]))\n",
    "\n",
    "        # Estimate the ATE using the Neural Network (MLP)\n",
    "        nn = MLPTRegressor(hidden_layer_sizes=(10, 10),\n",
    "                        learning_rate_init=.1,\n",
    "                        early_stopping=True,\n",
    "                        random_state=42)\n",
    "        te, lb, ub = nn.estimate_ate(X, treatment, y)\n",
    "        # Print all the treatment average effects\n",
    "        for treatment_level in range(len(te)):\n",
    "            print('ATE with Neural Network (MLP) on treatment level {}: {:.2f} ({:.2f}, {:.2f})'\\\n",
    "                  .format(treatment_labels[treatment_level + 1], te[treatment_level], lb[treatment_level], ub[treatment_level]))\n",
    "\n",
    "        # Estimate the ATE using the BaseXRegressor\n",
    "        xl = BaseXRegressor(learner=XGBRegressor(random_state=42))\n",
    "        te, lb, ub = xl.estimate_ate(X, treatment, y)\n",
    "        # Print all the treatment average effects\n",
    "        for treatment_level in range(len(te)):\n",
    "            print('ATE with BaseXRegressor using XGBoost on treatment level {}: {:.2f} ({:.2f}, {:.2f})'\\\n",
    "                  .format(treatment_labels[treatment_level + 1], te[treatment_level], lb[treatment_level], ub[treatment_level]))\n",
    "        \n",
    "        # Estimate the ATE using the BaseDRLearner\n",
    "        dr = BaseDRLearner(learner=XGBRegressor(random_state=42))\n",
    "        te, lb, ub = dr.estimate_ate(X, treatment, y)\n",
    "        # Print all the treatment average effects\n",
    "        for treatment_level in range(len(te)):\n",
    "            print('ATE with BaseDRLearner using XGBoost on treatment level {}: {:.2f} ({:.2f}, {:.2f})'\\\n",
    "                .format(treatment_labels[treatment_level + 1], te[treatment_level], lb[treatment_level], ub[treatment_level]))\n",
    "        \n",
    "        # Estimate the ATE using the BaseRLearner\n",
    "        rl = BaseRLearner(learner=XGBRegressor(random_state=42))\n",
    "        te, lb, ub = rl.estimate_ate(X, treatment, y)\n",
    "        # Print all the treatment average effects\n",
    "        for treatment_level in range(len(te)):\n",
    "            print('ATE with BaseRLearner using XGBoost on treatment level {}: {:.2f} ({:.2f}, {:.2f})'\\\n",
    "                .format(treatment_labels[treatment_level + 1], te[treatment_level], lb[treatment_level], ub[treatment_level]))\n",
    "            \n",
    "        # Print whitespace\n",
    "        print('\\n')\n",
    "        \n",
    "    elif treatment_col in multi_levels:\n",
    "        \n",
    "        # Create a dictionary mapping the recoded treatment levels to their original labels\n",
    "        treatment_labels = {0: 'Never', 1: 'Once', 2: 'More than once'}\n",
    "        \n",
    "        # Print the control group\n",
    "        print('Control Group is {} i.e. Never had ACE'.format(treatment_labels[0]))\n",
    "        \n",
    "        # Keep only the responses that are 1 or 2 or 3 (1 = Never, 2 = Once, 3 = More than once)\n",
    "        data = data[data[treatment_col].isin([1, 2, 3])]\n",
    "        # Recode the treatment and target variables\n",
    "        data[treatment_col] = data[treatment_col].map({1: 0, 2: 1, 3: 2})\n",
    "        \n",
    "        # Declare the treatment and target\n",
    "        treatment = data[treatment_col]\n",
    "        y = data[target_col]\n",
    "\n",
    "        # Declare X\n",
    "        X = data[feature_cols]\n",
    "        \n",
    "        # Declare the sample weights\n",
    "        sample_weights = data[sample_weights_col]\n",
    "\n",
    "        # Perform the analysis -----------------------------------------\n",
    "        \n",
    "        # Estimate the ATE using the LRS Regressor\n",
    "        learner_s = LRSRegressor()\n",
    "        te, lb, ub = learner_s.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "        # Print all the treatment average effects\n",
    "        for treatment_level in range(len(te)):\n",
    "            print('ATE with LRS Regressor on treatment {}: {:.2f} ({:.2f}, {:.2f})'\\\n",
    "                .format(treatment_labels[treatment_level + 1], te[treatment_level], lb[treatment_level], ub[treatment_level]))\n",
    "\n",
    "        # Estimate the ATE using the Neural Network (MLP)\n",
    "        nn = MLPTRegressor(hidden_layer_sizes=(10, 10),\n",
    "                        learning_rate_init=.1,\n",
    "                        early_stopping=True,\n",
    "                        random_state=42)\n",
    "        te, lb, ub = nn.estimate_ate(X, treatment, y)\n",
    "        # Print all the treatment average effects\n",
    "        for treatment_level in range(len(te)):\n",
    "            print('ATE with Neural Network (MLP) on treatment level {}: {:.2f} ({:.2f}, {:.2f})'\\\n",
    "                  .format(treatment_labels[treatment_level + 1], te[treatment_level], lb[treatment_level], ub[treatment_level]))\n",
    "\n",
    "        # Estimate the ATE using the BaseXRegressor\n",
    "        xl = BaseXRegressor(learner=XGBRegressor(random_state=42))\n",
    "        te, lb, ub = xl.estimate_ate(X, treatment, y)\n",
    "        # Print all the treatment average effects\n",
    "        for treatment_level in range(len(te)):\n",
    "            print('ATE with BaseXRegressor using XGBoost on treatment level {}: {:.2f} ({:.2f}, {:.2f})'\\\n",
    "                  .format(treatment_labels[treatment_level + 1], te[treatment_level], lb[treatment_level], ub[treatment_level]))\n",
    "        \n",
    "        # Estimate the ATE using the BaseDRLearner\n",
    "        dr = BaseDRLearner(learner=XGBRegressor(random_state=42))\n",
    "        te, lb, ub = dr.estimate_ate(X, treatment, y)\n",
    "        # Print all the treatment average effects\n",
    "        for treatment_level in range(len(te)):\n",
    "            print('ATE with BaseDRLearner using XGBoost on treatment level {}: {:.2f} ({:.2f}, {:.2f})'\\\n",
    "                .format(treatment_labels[treatment_level + 1], te[treatment_level], lb[treatment_level], ub[treatment_level]))\n",
    "        \n",
    "        # Estimate the ATE using the BaseRLearner\n",
    "        rl = BaseRLearner(learner=XGBRegressor(random_state=42))\n",
    "        te, lb, ub = rl.estimate_ate(X, treatment, y)\n",
    "        # Print all the treatment average effects\n",
    "        for treatment_level in range(len(te)):\n",
    "            print('ATE with BaseRLearner using XGBoost on treatment level {}: {:.2f} ({:.2f}, {:.2f})'\\\n",
    "                .format(treatment_labels[treatment_level + 1], te[treatment_level], lb[treatment_level], ub[treatment_level]))\n",
    "            \n",
    "        # Print whitespace\n",
    "        print('\\n')\n",
    "    else:\n",
    "        # Create a dictionary mapping the recoded treatment levels to their original labels\n",
    "        treatment_labels = {0: 'No', 1: 'Yes'}\n",
    "        \n",
    "        # Print the control group\n",
    "        print('Control Group is {} i.e. No Answer to ACE Question'.format(treatment_labels[0]))\n",
    "        \n",
    "        # Keep only the responses that are 1 or 2 or 3 (1 = Yes, 2 = No)\n",
    "        data = data[data[treatment_col].isin([1, 2])]\n",
    "        \n",
    "        # Recode the treatment variable\n",
    "        data[treatment_col] = data[treatment_col].map({2: 0, 1: 1})\n",
    "        \n",
    "        # Declare the treatment and target\n",
    "        treatment = data[treatment_col]\n",
    "        y = data[target_col]\n",
    "\n",
    "        # Declare X\n",
    "        X = data[feature_cols]\n",
    "        \n",
    "        # Declare the sample weights\n",
    "        sample_weights = data[sample_weights_col]\n",
    "        \n",
    "        # Calculate the propensity score\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X, y)\n",
    "        e = model.predict_proba(X)[:, 1]\n",
    "        \n",
    "        # Perform the analysis -----------------------------------------\n",
    "        \n",
    "        # Estimate the ATE using the LRS Regressor\n",
    "        learner_s = LRSRegressor()\n",
    "        te, lb, ub = learner_s.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "        # Print all the treatment average effects\n",
    "        for treatment_level in range(len(te)):\n",
    "            print('ATE with LRS Regressor on treatment {}: {:.2f} ({:.2f}, {:.2f})'\\\n",
    "                .format(treatment_labels[treatment_level + 1], te[treatment_level], lb[treatment_level], ub[treatment_level]))\n",
    "\n",
    "        # Estimate the ATE using the Neural Network (MLP)\n",
    "        nn = MLPTRegressor(hidden_layer_sizes=(10, 10),\n",
    "                        learning_rate_init=.1,\n",
    "                        early_stopping=True,\n",
    "                        random_state=42)\n",
    "        te, lb, ub = nn.estimate_ate(X, treatment, y)\n",
    "        # Print all the treatment average effects\n",
    "        for treatment_level in range(len(te)):\n",
    "            print('ATE with Neural Network (MLP) on treatment level {}: {:.2f} ({:.2f}, {:.2f})'\\\n",
    "                  .format(treatment_labels[treatment_level + 1], te[treatment_level], lb[treatment_level], ub[treatment_level]))\n",
    "\n",
    "        # Estimate the ATE using the BaseXRegressor\n",
    "        xl = BaseXRegressor(learner=XGBRegressor(random_state=42))\n",
    "        te, lb, ub = xl.estimate_ate(X, treatment, y, e)\n",
    "        # Print all the treatment average effects\n",
    "        for treatment_level in range(len(te)):\n",
    "            print('ATE with BaseXRegressor using XGBoost on treatment level {}: {:.2f} ({:.2f}, {:.2f})'\\\n",
    "                  .format(treatment_labels[treatment_level + 1], te[treatment_level], lb[treatment_level], ub[treatment_level]))\n",
    "        \n",
    "        # Estimate the ATE using the BaseDRLearner\n",
    "        dr = BaseDRLearner(learner=XGBRegressor(random_state=42))\n",
    "        te, lb, ub = dr.estimate_ate(X, treatment, y, e)\n",
    "        # Print all the treatment average effects\n",
    "        for treatment_level in range(len(te)):\n",
    "            print('ATE with BaseDRLearner using XGBoost on treatment level {}: {:.2f} ({:.2f}, {:.2f})'\\\n",
    "                .format(treatment_labels[treatment_level + 1], te[treatment_level], lb[treatment_level], ub[treatment_level]))\n",
    "        \n",
    "        # Estimate the ATE using the BaseRLearner\n",
    "        rl = BaseRLearner(learner=XGBRegressor(random_state=42))\n",
    "        te, lb, ub = rl.estimate_ate(X, treatment, y, e)\n",
    "        # Print all the treatment average effects\n",
    "        for treatment_level in range(len(te)):\n",
    "            print('ATE with BaseRLearner using XGBoost on treatment level {}: {:.2f} ({:.2f}, {:.2f})'\\\n",
    "                .format(treatment_labels[treatment_level + 1], te[treatment_level], lb[treatment_level], ub[treatment_level]))\n",
    "        \n",
    "        # Print whitespace\n",
    "        print('\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_target(data, target_col):\n",
    "    # If Target is ADDEPEV3, recode the target variable to binary\n",
    "    if target_col == 'ADDEPEV3':\n",
    "        data[target_col] = data[target_col].map({1: 1, 2: 0})\n",
    "    \n",
    "    # If target is MENTHLTH, filter out responses that are 77 or 99 and recode 88 to 0\n",
    "    if target_col == 'MENTHLTH':\n",
    "        \n",
    "        # Filter out responses that are 77\n",
    "        data = data[data[target_col] != 77]\n",
    "        \n",
    "        # Filter out responses that are 99\n",
    "        data = data[data[target_col] != 99]\n",
    "        \n",
    "        # Replace the value 88 to 0 and leave the rest as they are\n",
    "        data[target_col] = data[target_col].replace({88: 0})\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing analysis for target ADDEPEV3 and treatment ACEDEPRS\n",
      "Control Group is No i.e. No Answer to ACE Question\n",
      "ATE with LRS Regressor on treatment Yes: 0.28 (0.27, 0.29)\n",
      "ATE with Neural Network (MLP) on treatment level Yes: 0.30 (0.29, 0.31)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Yes: 0.26 (0.25, 0.27)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Yes: 0.26 (0.25, 0.27)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Yes: 0.25 (0.25, 0.25)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACEDRINK\n",
      "Control Group is No i.e. No Answer to ACE Question\n",
      "ATE with LRS Regressor on treatment Yes: 0.13 (0.12, 0.14)\n",
      "ATE with Neural Network (MLP) on treatment level Yes: 0.14 (0.13, 0.14)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Yes: 0.12 (0.11, 0.12)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Yes: 0.11 (0.11, 0.12)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Yes: 0.11 (0.11, 0.11)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACEDRUGS\n",
      "Control Group is No i.e. No Answer to ACE Question\n",
      "ATE with LRS Regressor on treatment Yes: 0.18 (0.16, 0.19)\n",
      "ATE with Neural Network (MLP) on treatment level Yes: 0.19 (0.18, 0.21)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Yes: 0.16 (0.15, 0.17)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Yes: 0.16 (0.15, 0.17)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Yes: 0.12 (0.12, 0.13)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACEPRISN\n",
      "Control Group is No i.e. No Answer to ACE Question\n",
      "ATE with LRS Regressor on treatment Yes: 0.14 (0.12, 0.15)\n",
      "ATE with Neural Network (MLP) on treatment level Yes: 0.09 (0.08, 0.11)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Yes: 0.12 (0.10, 0.13)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Yes: 0.11 (0.10, 0.12)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Yes: 0.08 (0.08, 0.08)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACEDIVRC\n",
      "Control Group is Yes i.e. Parents Married\n",
      "ATE with LRS Regressor on treatment No: 0.07 (0.07, 0.08)\n",
      "ATE with LRS Regressor on treatment Parents not married: 0.10 (0.07, 0.13)\n",
      "ATE with Neural Network (MLP) on treatment level No: 0.07 (0.06, 0.08)\n",
      "ATE with Neural Network (MLP) on treatment level Parents not married: 0.13 (0.10, 0.16)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level No: 0.06 (0.05, 0.07)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Parents not married: 0.06 (0.03, 0.08)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level No: 0.06 (0.05, 0.07)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Parents not married: 0.03 (0.00, 0.06)\n",
      "ATE with BaseRLearner using XGBoost on treatment level No: 0.06 (0.06, 0.06)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Parents not married: 0.06 (0.06, 0.06)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACEPUNCH\n",
      "Control Group is Never i.e. Never had ACE\n",
      "ATE with LRS Regressor on treatment Once: 0.09 (0.07, 0.11)\n",
      "ATE with LRS Regressor on treatment More than once: 0.16 (0.15, 0.17)\n",
      "ATE with Neural Network (MLP) on treatment level Once: 0.07 (0.05, 0.09)\n",
      "ATE with Neural Network (MLP) on treatment level More than once: 0.14 (0.13, 0.15)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Once: 0.08 (0.07, 0.10)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level More than once: 0.14 (0.13, 0.15)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Once: 0.08 (0.06, 0.10)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level More than once: 0.14 (0.12, 0.15)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Once: 0.08 (0.08, 0.08)\n",
      "ATE with BaseRLearner using XGBoost on treatment level More than once: 0.13 (0.13, 0.13)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACEHURT1\n",
      "Control Group is Never i.e. Never had ACE\n",
      "ATE with LRS Regressor on treatment Once: 0.09 (0.08, 0.10)\n",
      "ATE with LRS Regressor on treatment More than once: 0.16 (0.15, 0.17)\n",
      "ATE with Neural Network (MLP) on treatment level Once: 0.12 (0.10, 0.13)\n",
      "ATE with Neural Network (MLP) on treatment level More than once: 0.18 (0.17, 0.19)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Once: 0.09 (0.07, 0.10)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level More than once: 0.14 (0.13, 0.15)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Once: 0.09 (0.07, 0.10)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level More than once: 0.14 (0.13, 0.15)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Once: 0.08 (0.08, 0.08)\n",
      "ATE with BaseRLearner using XGBoost on treatment level More than once: 0.14 (0.14, 0.14)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACESWEAR\n",
      "Control Group is Never i.e. Never had ACE\n",
      "ATE with LRS Regressor on treatment Once: 0.07 (0.05, 0.08)\n",
      "ATE with LRS Regressor on treatment More than once: 0.18 (0.17, 0.19)\n",
      "ATE with Neural Network (MLP) on treatment level Once: 0.10 (0.08, 0.11)\n",
      "ATE with Neural Network (MLP) on treatment level More than once: 0.18 (0.17, 0.19)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Once: 0.07 (0.06, 0.08)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level More than once: 0.17 (0.16, 0.18)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Once: 0.07 (0.06, 0.09)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level More than once: 0.17 (0.16, 0.18)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Once: 0.05 (0.05, 0.05)\n",
      "ATE with BaseRLearner using XGBoost on treatment level More than once: 0.17 (0.17, 0.17)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACETOUCH\n",
      "Control Group is Never i.e. Never had ACE\n",
      "ATE with LRS Regressor on treatment Once: 0.17 (0.15, 0.19)\n",
      "ATE with LRS Regressor on treatment More than once: 0.27 (0.25, 0.28)\n",
      "ATE with Neural Network (MLP) on treatment level Once: 0.16 (0.14, 0.18)\n",
      "ATE with Neural Network (MLP) on treatment level More than once: 0.27 (0.26, 0.29)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Once: 0.14 (0.12, 0.16)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level More than once: 0.22 (0.21, 0.24)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Once: 0.15 (0.13, 0.17)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level More than once: 0.23 (0.21, 0.24)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Once: 0.14 (0.14, 0.14)\n",
      "ATE with BaseRLearner using XGBoost on treatment level More than once: 0.22 (0.22, 0.22)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACETTHEM\n",
      "Control Group is Never i.e. Never had ACE\n",
      "ATE with LRS Regressor on treatment Once: 0.18 (0.16, 0.20)\n",
      "ATE with LRS Regressor on treatment More than once: 0.27 (0.26, 0.29)\n",
      "ATE with Neural Network (MLP) on treatment level Once: 0.12 (0.10, 0.14)\n",
      "ATE with Neural Network (MLP) on treatment level More than once: 0.32 (0.31, 0.34)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Once: 0.16 (0.14, 0.18)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level More than once: 0.24 (0.22, 0.25)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Once: 0.17 (0.15, 0.19)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level More than once: 0.23 (0.22, 0.25)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Once: 0.16 (0.16, 0.16)\n",
      "ATE with BaseRLearner using XGBoost on treatment level More than once: 0.23 (0.23, 0.23)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACEHVSEX\n",
      "Control Group is Never i.e. Never had ACE\n",
      "ATE with LRS Regressor on treatment Once: 0.23 (0.20, 0.26)\n",
      "ATE with LRS Regressor on treatment More than once: 0.30 (0.28, 0.32)\n",
      "ATE with Neural Network (MLP) on treatment level Once: 0.23 (0.20, 0.26)\n",
      "ATE with Neural Network (MLP) on treatment level More than once: 0.33 (0.30, 0.35)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Once: 0.18 (0.15, 0.20)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level More than once: 0.25 (0.24, 0.27)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Once: 0.20 (0.17, 0.22)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level More than once: 0.25 (0.23, 0.27)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Once: 0.18 (0.18, 0.18)\n",
      "ATE with BaseRLearner using XGBoost on treatment level More than once: 0.25 (0.25, 0.25)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACEDEPRS\n",
      "Control Group is No i.e. No Answer to ACE Question\n",
      "ATE with LRS Regressor on treatment Yes: 4.64 (4.43, 4.85)\n",
      "ATE with Neural Network (MLP) on treatment level Yes: 4.16 (3.96, 4.36)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Yes: 4.16 (3.96, 4.35)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Yes: 4.24 (4.04, 4.43)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Yes: 3.48 (3.48, 3.48)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACEDRINK\n",
      "Control Group is No i.e. No Answer to ACE Question\n",
      "ATE with LRS Regressor on treatment Yes: 2.57 (2.40, 2.75)\n",
      "ATE with Neural Network (MLP) on treatment level Yes: 3.22 (3.05, 3.39)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Yes: 2.27 (2.10, 2.43)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Yes: 2.22 (2.05, 2.39)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Yes: 1.77 (1.77, 1.77)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACEDRUGS\n",
      "Control Group is No i.e. No Answer to ACE Question\n",
      "ATE with LRS Regressor on treatment Yes: 3.81 (3.53, 4.09)\n",
      "ATE with Neural Network (MLP) on treatment level Yes: 4.06 (3.79, 4.34)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Yes: 3.17 (2.91, 3.43)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Yes: 3.17 (2.91, 3.43)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Yes: 2.96 (2.96, 2.96)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACEPRISN\n",
      "Control Group is No i.e. No Answer to ACE Question\n",
      "ATE with LRS Regressor on treatment Yes: 3.31 (2.98, 3.64)\n",
      "ATE with Neural Network (MLP) on treatment level Yes: 3.68 (3.36, 4.00)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Yes: 2.70 (2.40, 3.01)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Yes: 2.62 (2.31, 2.93)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Yes: 2.56 (2.56, 2.57)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACEDIVRC\n",
      "Control Group is Yes i.e. Parents Married\n",
      "ATE with LRS Regressor on treatment No: 1.64 (1.47, 1.81)\n",
      "ATE with LRS Regressor on treatment Parents not married: 2.77 (2.02, 3.51)\n",
      "ATE with Neural Network (MLP) on treatment level No: 1.04 (0.87, 1.21)\n",
      "ATE with Neural Network (MLP) on treatment level Parents not married: 1.43 (0.72, 2.14)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level No: 1.32 (1.15, 1.48)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Parents not married: 1.82 (1.23, 2.42)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level No: 1.29 (1.13, 1.46)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Parents not married: 2.06 (1.41, 2.71)\n",
      "ATE with BaseRLearner using XGBoost on treatment level No: 1.29 (1.29, 1.29)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Parents not married: 1.81 (1.81, 1.81)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACEPUNCH\n",
      "Control Group is Never i.e. Never had ACE\n",
      "ATE with LRS Regressor on treatment Once: 1.69 (1.31, 2.07)\n",
      "ATE with LRS Regressor on treatment More than once: 3.25 (3.01, 3.50)\n",
      "ATE with Neural Network (MLP) on treatment level Once: 0.70 (0.32, 1.08)\n",
      "ATE with Neural Network (MLP) on treatment level More than once: 2.03 (1.79, 2.27)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Once: 1.45 (1.11, 1.79)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level More than once: 2.83 (2.59, 3.06)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Once: 1.64 (1.29, 1.98)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level More than once: 2.79 (2.55, 3.02)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Once: 1.50 (1.50, 1.50)\n",
      "ATE with BaseRLearner using XGBoost on treatment level More than once: 2.79 (2.79, 2.79)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACEHURT1\n",
      "Control Group is Never i.e. Never had ACE\n",
      "ATE with LRS Regressor on treatment Once: 1.63 (1.35, 1.92)\n",
      "ATE with LRS Regressor on treatment More than once: 3.31 (3.10, 3.51)\n",
      "ATE with Neural Network (MLP) on treatment level Once: 1.22 (0.94, 1.50)\n",
      "ATE with Neural Network (MLP) on treatment level More than once: 2.89 (2.69, 3.10)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Once: 1.50 (1.23, 1.77)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level More than once: 2.87 (2.68, 3.07)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Once: 1.41 (1.13, 1.68)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level More than once: 2.81 (2.61, 3.00)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Once: 1.43 (1.43, 1.43)\n",
      "ATE with BaseRLearner using XGBoost on treatment level More than once: 2.84 (2.84, 2.84)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACESWEAR\n",
      "Control Group is Never i.e. Never had ACE\n",
      "ATE with LRS Regressor on treatment Once: 1.31 (1.01, 1.61)\n",
      "ATE with LRS Regressor on treatment More than once: 3.48 (3.32, 3.65)\n",
      "ATE with Neural Network (MLP) on treatment level Once: 1.42 (1.13, 1.72)\n",
      "ATE with Neural Network (MLP) on treatment level More than once: 3.37 (3.21, 3.53)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Once: 1.23 (0.96, 1.50)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level More than once: 3.20 (3.04, 3.36)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Once: 1.06 (0.78, 1.34)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level More than once: 3.17 (3.02, 3.33)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Once: 0.93 (0.93, 0.93)\n",
      "ATE with BaseRLearner using XGBoost on treatment level More than once: 3.15 (3.15, 3.16)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACETOUCH\n",
      "Control Group is Never i.e. Never had ACE\n",
      "ATE with LRS Regressor on treatment Once: 2.82 (2.42, 3.21)\n",
      "ATE with LRS Regressor on treatment More than once: 4.62 (4.30, 4.94)\n",
      "ATE with Neural Network (MLP) on treatment level Once: 2.58 (2.18, 2.97)\n",
      "ATE with Neural Network (MLP) on treatment level More than once: 3.82 (3.50, 4.13)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Once: 2.37 (2.01, 2.73)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level More than once: 3.74 (3.44, 4.04)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Once: 2.55 (2.18, 2.92)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level More than once: 3.91 (3.60, 4.21)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Once: 2.37 (2.36, 2.37)\n",
      "ATE with BaseRLearner using XGBoost on treatment level More than once: 3.70 (3.70, 3.70)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACETTHEM\n",
      "Control Group is Never i.e. Never had ACE\n",
      "ATE with LRS Regressor on treatment Once: 3.08 (2.62, 3.53)\n",
      "ATE with LRS Regressor on treatment More than once: 5.07 (4.68, 5.46)\n",
      "ATE with Neural Network (MLP) on treatment level Once: 1.89 (1.44, 2.33)\n",
      "ATE with Neural Network (MLP) on treatment level More than once: 4.60 (4.22, 4.98)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Once: 2.80 (2.40, 3.20)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level More than once: 4.16 (3.80, 4.51)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Once: 2.85 (2.43, 3.27)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level More than once: 4.06 (3.70, 4.42)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Once: 2.80 (2.79, 2.80)\n",
      "ATE with BaseRLearner using XGBoost on treatment level More than once: 4.13 (4.13, 4.13)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACEHVSEX\n",
      "Control Group is Never i.e. Never had ACE\n",
      "ATE with LRS Regressor on treatment Once: 4.25 (3.58, 4.91)\n",
      "ATE with LRS Regressor on treatment More than once: 5.77 (5.26, 6.28)\n",
      "ATE with Neural Network (MLP) on treatment level Once: 4.52 (3.87, 5.18)\n",
      "ATE with Neural Network (MLP) on treatment level More than once: 5.49 (4.99, 5.98)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level Once: 3.34 (2.78, 3.89)\n",
      "ATE with BaseXRegressor using XGBoost on treatment level More than once: 4.71 (4.25, 5.16)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level Once: 3.28 (2.68, 3.88)\n",
      "ATE with BaseDRLearner using XGBoost on treatment level More than once: 4.78 (4.31, 5.24)\n",
      "ATE with BaseRLearner using XGBoost on treatment level Once: 3.33 (3.33, 3.33)\n",
      "ATE with BaseRLearner using XGBoost on treatment level More than once: 4.66 (4.66, 4.67)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Declare the feature columns\n",
    "feature_cols = ['_AGE_G', '_SEX', '_EDUCAG', '_INCOMG1']\n",
    "\n",
    "# Declare the target columns\n",
    "target_cols = ['ADDEPEV3', 'MENTHLTH']\n",
    "\n",
    "# Declare the treatment columns\n",
    "treatment_cols = ['ACEDEPRS', 'ACEDRINK', 'ACEDRUGS', 'ACEPRISN',\n",
    "       'ACEDIVRC', 'ACEPUNCH', 'ACEHURT1', 'ACESWEAR', 'ACETOUCH', 'ACETTHEM',\n",
    "       'ACEHVSEX']\n",
    "\n",
    "# Declare the sample weights column\n",
    "sample_weights_col = 'FINALWT'\n",
    "\n",
    "# Iterate over all combinations of target and treatment columns\n",
    "for target in target_cols:\n",
    "    # Recode the target variable\n",
    "    ace_data_df = recode_target(ace_data, target)\n",
    "    for treatment in treatment_cols:\n",
    "        print(f\"Performing analysis for target {target} and treatment {treatment}\")\n",
    "        perform_analysis(ace_data_df, target, treatment, feature_cols, sample_weights_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_results(learner, X, treatment, y, treatment_labels, learner_name):\n",
    "#     te, lb, ub = learner.estimate_ate(X, treatment, y)\n",
    "#     # Print all the treatment average effects\n",
    "#     for treatment_level in range(len(te)):\n",
    "#         print('ATE with {} on treatment level {}: {:.2f} ({:.2f}, {:.2f})'\\\n",
    "#               .format(learner_name, treatment_labels[treatment_level + 1], te[treatment_level], lb[treatment_level], ub[treatment_level]))\n",
    "\n",
    "# def perform_analysis(data, target, treatment, feature_cols, sample_weights_col):\n",
    "#     # Extract the relevant data\n",
    "#     X = data[feature_cols]\n",
    "#     y = data[target]\n",
    "#     treatment = data[treatment]\n",
    "#     sample_weights = data[sample_weights_col]\n",
    "\n",
    "#     # Perform the analysis -----------------------------------------\n",
    "    \n",
    "#     # Estimate the ATE using the LRS Regressor\n",
    "#     learner_s = LRSRegressor()\n",
    "#     generate_results(learner_s, X, treatment, y, 'LRS Regressor')\n",
    "\n",
    "#     # Estimate the ATE using the Neural Network (MLP)\n",
    "#     nn = MLPTRegressor(hidden_layer_sizes=(10, 10),\n",
    "#                     learning_rate_init=.1,\n",
    "#                     early_stopping=True,\n",
    "#                     random_state=42)\n",
    "#     generate_results(nn, X, treatment, y, 'Neural Network (MLP)')\n",
    "\n",
    "#     # Estimate the ATE using the BaseXRegressor\n",
    "#     xl = BaseXRegressor(learner=XGBRegressor(random_state=42))\n",
    "#     generate_results(xl, X, treatment, y, 'BaseXRegressor using XGBoost')\n",
    "\n",
    "#     # Estimate the ATE using the BaseDRLearner\n",
    "#     dr = BaseDRLearner(learner=XGBRegressor(random_state=42))\n",
    "#     generate_results(dr, X, treatment, y, 'BaseDRLearner using XGBoost')\n",
    "\n",
    "#     # Estimate the ATE using the BaseRLearner\n",
    "#     rl = BaseRLearner(learner=XGBRegressor(random_state=42))\n",
    "#     generate_results(rl, X, treatment, y, 'BaseRLearner using XGBoost')\n",
    "    \n",
    "#     # Print whitespace\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Declare the feature columns\n",
    "# feature_cols = ['_AGE_G', '_SEX', '_EDUCAG', '_INCOMG1']\n",
    "\n",
    "# # Declare the target columns\n",
    "# target_cols = ['ADDEPEV3', 'MENTHLTH']\n",
    "\n",
    "# # Declare the treatment columns\n",
    "# treatment_cols = ['ACEDEPRS', 'ACEDRINK', 'ACEDRUGS', 'ACEPRISN',\n",
    "#        'ACEDIVRC', 'ACEPUNCH', 'ACEHURT1', 'ACESWEAR', 'ACETOUCH', 'ACETTHEM',\n",
    "#        'ACEHVSEX']\n",
    "\n",
    "# # Declare the sample weights column\n",
    "# sample_weights_col = 'FINALWT'\n",
    "\n",
    "# # Recode the target columns\n",
    "# for target in target_cols:\n",
    "#     ace_data = recode_target(ace_data, target)\n",
    "\n",
    "# # Iterate over all combinations of target and treatment columns\n",
    "# for target in target_cols:\n",
    "#     for treatment in treatment_cols:\n",
    "#         print(f\"Performing analysis for target {target} and treatment {treatment}\")\n",
    "#         perform_analysis(ace_data, target, treatment, feature_cols, sample_weights_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copilot on Interpretation:\n",
    "\n",
    "For the binary target ADDEPEV3 with treatment ACEDEPRS:\n",
    "\n",
    "The Average Treatment Effect (ATE) is a measure of the difference in mean (average) outcomes between units that received the treatment and those that did not. In this case, the ATE is the difference in the average outcome of ADDEPEV3 (whether a person has experienced a depressive episode) between those who have experienced ACEDEPRS (a form of adverse childhood experience) and those who have not.\n",
    "\n",
    "The results from the different models (LRS Regressor, Neural Network, BaseXRegressor using XGBoost, and BaseRRegressor using XGBoost) are all around 0.25 to 0.30. This suggests that, on average, experiencing ACEDEPRS increases the likelihood of having a depressive episode (ADDEPEV3) by about 25% to 30%. The numbers in parentheses are the lower and upper bounds of a 95% confidence interval for the ATE, indicating the range within which we can be 95% confident that the true ATE lies.\n",
    "\n",
    "In simpler terms: These results suggest that people who have experienced this particular adverse childhood experience are about 25% to 30% more likely to have had a depressive episode.\n",
    "\n",
    "For the continuous target MENTHLTH with treatment ACEHVSEX:\n",
    "\n",
    "The interpretation is similar, but now the ATE represents the difference in the average number of days of poor mental health (MENTHLTH) between those who have experienced ACEHVSEX (another form of adverse childhood experience) and those who have not.\n",
    "\n",
    "The results from the different models suggest that, on average, experiencing ACEHVSEX increases the number of days of poor mental health by about 10 to 13 days. The BaseRRegressor using XGBoost model seems to be an outlier with an ATE of 0.26, which might suggest some issue with the model or the data.\n",
    "\n",
    "In simpler terms: These results suggest that people who have experienced this particular adverse childhood experience have, on average, 10 to 13 more days of poor mental health."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Example with Drugs as Treatment and Mental Health as Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filter out rows that have `nan` values in the 'ACEDRUGS' or 'MENTHLTH' columns\n",
    "# ace_data = ace_data.dropna(subset=['ACEDRUGS', 'MENTHLTH'])\n",
    "\n",
    "# # Filter the dataset to only include rows where the 'ACEDRUGS' column is less than 2\n",
    "# ace_data = ace_data[ace_data['ACEDRUGS'] < 3] # Only two levels of treatment\n",
    "\n",
    "# # Declare the treatment\n",
    "# treatment = ace_data['ACEDRUGS']\n",
    "\n",
    "# # Declare the target\n",
    "# # y = ace_data['MENTHLTH']\n",
    "# y = ace_data['ACEDEPRS']\n",
    "\n",
    "# # # Subtract 1 from the treatment column\n",
    "# treatment = treatment - 1 \n",
    "# # TODO I need to confirm what 0 and 1 should mean for CausalML i.e. YES and NO or NO and YES\n",
    "\n",
    "# print(treatment.unique())\n",
    "\n",
    "# # Declare X\n",
    "# X = ace_data[['_AGE_G', '_SEX', '_EDUCAG', '_INCOMG1']]\n",
    "\n",
    "# # Print the shapes of X, treatment, and y\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "# print(treatment.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propensity Score\n",
    "Propensity score, which is the probability of receiving the treatment given the observed features.\n",
    "\n",
    "In the context of causal inference, the propensity score is a balancing score: conditional on the propensity score, the distribution of observed covariates will be the same between treated and untreated subjects.\n",
    "\n",
    "To create e with non-synthetic data, you would typically use a binary classification model where the features are your covariates and the target is whether or not the subject received treatment. The predicted probability of receiving treatment is your propensity score.\n",
    "\n",
    "This code fits a logistic regression model to predict the treatment given the features, and then uses this model to compute the propensity score. Note that this is a very basic example and in practice you might need to consider more sophisticated models or methods to estimate the propensity score, depending on the complexity of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the propensity score (basic and prompt engineered could be wrong)\n",
    "# model = LogisticRegression()\n",
    "# model.fit(X, y)\n",
    "\n",
    "# # The propensity score\n",
    "# e = model.predict_proba(X)[:, 1]\n",
    "# print(len(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner_s = LRSRegressor()\n",
    "# ate_s = learner_s.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "# print(ate_s)\n",
    "# print('ATE estimate: {:.03f}'.format(ate_s[0][0]))\n",
    "# print('ATE lower bound: {:.03f}'.format(ate_s[1][0]))\n",
    "# print('ATE upper bound: {:.03f}'.format(ate_s[2][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn = MLPTRegressor(hidden_layer_sizes=(10, 10),\n",
    "#                  learning_rate_init=.1,\n",
    "#                  early_stopping=True,\n",
    "#                  random_state=42)\n",
    "# te, lb, ub = nn.estimate_ate(X, treatment, y)\n",
    "# print('Average Treatment Effect (Neural Network (MLP)): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xl = BaseXRegressor(learner=XGBRegressor(random_state=42))\n",
    "# te, lb, ub = xl.estimate_ate(X, treatment, y, e)\n",
    "# print('Average Treatment Effect (BaseXRegressor using XGBoost): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rl = BaseRRegressor(learner=XGBRegressor(random_state=42))\n",
    "# te, lb, ub =  rl.estimate_ate(X=X, p=e, treatment=treatment, y=y)\n",
    "# print('Average Treatment Effect (BaseRRegressor using XGBoost): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
