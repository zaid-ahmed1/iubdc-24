{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\OneDrive\\Documents\\Projects\\iubdc\\repo\\iubdc_2024\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Failed to import duecredit due to No module named 'duecredit'\n"
     ]
    }
   ],
   "source": [
    "from causalml.dataset import synthetic_data\n",
    "from causalml.inference.meta import BaseSRegressor, BaseTRegressor, BaseXRegressor, BaseRRegressor, LRSRegressor\n",
    "from causalml.inference.meta import XGBTRegressor, MLPTRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Read in Ace data\n",
    "ace_data = pd.read_csv('ace_data.csv')\n",
    "\n",
    "# y, X, treatment, _, _, e = synthetic_data(mode=1, n=1000, p=5, sigma=1.0)\n",
    "\n",
    "# # Print the shape of the data\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "# print(treatment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['GENHLTH', 'MARITAL', '_SEX', 'MENTHLTH', '_EDUCAG', '_INCOMG1',\n",
      "       'POORHLTH', 'ADDEPEV3', '_AGEG5YR', '_AGE65YR', '_AGE80', '_AGE_G',\n",
      "       'DECIDE', 'DIFFALON', 'ACEDEPRS', 'ACEDRINK', 'ACEDRUGS', 'ACEPRISN',\n",
      "       'ACEDIVRC', 'ACEPUNCH', 'ACEHURT1', 'ACESWEAR', 'ACETOUCH', 'ACETTHEM',\n",
      "       'ACEHVSEX'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Get the column names of ace_data\n",
    "column_names = ace_data.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_analysis(data, target_col, treatment_col, feature_cols):\n",
    "    # Preprocess the data\n",
    "    data = data.dropna(subset=[treatment_col, target_col])\n",
    "    \n",
    "    # Filter out unwanted responses\n",
    "    data = data[data[treatment_col].isin([1, 2])]\n",
    "    \n",
    "    if target_col == 'ADDEPEV3':\n",
    "        data = data[data[target_col].isin([1, 2])]\n",
    "\n",
    "    # Recode the treatment and target variables\n",
    "    data[treatment_col] = data[treatment_col].map({1: 1, 2: 0})\n",
    "    \n",
    "    if target_col == 'ADDEPEV3':\n",
    "        data[target_col] = data[target_col].map({1: 1, 2: 0})\n",
    "\n",
    "    # Declare the treatment and target\n",
    "    treatment = data[treatment_col]\n",
    "    y = data[target_col]\n",
    "\n",
    "    # Declare X\n",
    "    X = data[feature_cols]\n",
    "\n",
    "    # Calculate the propensity score\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "    e = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    # Perform the analysis\n",
    "    learner_s = LRSRegressor()\n",
    "    te, lb, ub = learner_s.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "    print('Average Treatment Effect (LRS Regressor): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))\n",
    "\n",
    "    nn = MLPTRegressor(hidden_layer_sizes=(10, 10),\n",
    "                     learning_rate_init=.1,\n",
    "                     early_stopping=True,\n",
    "                     random_state=42)\n",
    "    te, lb, ub = nn.estimate_ate(X, treatment, y)\n",
    "    print('Average Treatment Effect (Neural Network (MLP)): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))\n",
    "\n",
    "    xl = BaseXRegressor(learner=XGBRegressor(random_state=42))\n",
    "    te, lb, ub = xl.estimate_ate(X, treatment, y, e)\n",
    "    print('Average Treatment Effect (BaseXRegressor using XGBoost): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))\n",
    "\n",
    "    rl = BaseRRegressor(learner=XGBRegressor(random_state=42))\n",
    "    te, lb, ub =  rl.estimate_ate(X=X, p=e, treatment=treatment, y=y)\n",
    "    print('Average Treatment Effect (BaseRRegressor using XGBoost): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))\n",
    "    \n",
    "    # Print whitespace\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing analysis for target ADDEPEV3 and treatment ACEDEPRS\n",
      "Average Treatment Effect (LRS Regressor): 0.28 (0.27, 0.29)\n",
      "Average Treatment Effect (Neural Network (MLP)): 0.30 (0.29, 0.31)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): 0.26 (0.25, 0.27)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): 0.25 (0.25, 0.25)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACEDRINK\n",
      "Average Treatment Effect (LRS Regressor): 0.13 (0.12, 0.14)\n",
      "Average Treatment Effect (Neural Network (MLP)): 0.14 (0.13, 0.14)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): 0.12 (0.11, 0.12)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): 0.11 (0.11, 0.11)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACEDRUGS\n",
      "Average Treatment Effect (LRS Regressor): 0.18 (0.16, 0.19)\n",
      "Average Treatment Effect (Neural Network (MLP)): 0.19 (0.18, 0.21)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): 0.16 (0.15, 0.17)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): 0.13 (0.13, 0.13)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACEPRISN\n",
      "Average Treatment Effect (LRS Regressor): 0.14 (0.12, 0.15)\n",
      "Average Treatment Effect (Neural Network (MLP)): 0.09 (0.08, 0.11)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): 0.12 (0.10, 0.13)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): 0.08 (0.08, 0.08)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACEDIVRC\n",
      "Average Treatment Effect (LRS Regressor): 0.07 (0.07, 0.08)\n",
      "Average Treatment Effect (Neural Network (MLP)): 0.07 (0.06, 0.08)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): 0.06 (0.05, 0.07)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): 0.06 (0.06, 0.06)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACEPUNCH\n",
      "Average Treatment Effect (LRS Regressor): -0.09 (-0.11, -0.07)\n",
      "Average Treatment Effect (Neural Network (MLP)): -0.07 (-0.09, -0.05)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): -0.08 (-0.10, -0.06)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): -0.01 (-0.01, -0.01)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACEHURT1\n",
      "Average Treatment Effect (LRS Regressor): -0.09 (-0.10, -0.08)\n",
      "Average Treatment Effect (Neural Network (MLP)): -0.12 (-0.13, -0.11)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): -0.09 (-0.10, -0.07)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): -0.01 (-0.01, -0.01)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACESWEAR\n",
      "Average Treatment Effect (LRS Regressor): -0.07 (-0.08, -0.05)\n",
      "Average Treatment Effect (Neural Network (MLP)): -0.10 (-0.11, -0.08)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): -0.07 (-0.08, -0.05)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): -0.01 (-0.01, -0.01)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACETOUCH\n",
      "Average Treatment Effect (LRS Regressor): -0.17 (-0.19, -0.15)\n",
      "Average Treatment Effect (Neural Network (MLP)): -0.16 (-0.18, -0.14)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): -0.14 (-0.16, -0.12)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): -0.01 (-0.01, -0.01)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACETTHEM\n",
      "Average Treatment Effect (LRS Regressor): -0.18 (-0.20, -0.16)\n",
      "Average Treatment Effect (Neural Network (MLP)): -0.12 (-0.15, -0.10)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): -0.16 (-0.18, -0.14)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): -0.01 (-0.01, -0.01)\n",
      "\n",
      "\n",
      "Performing analysis for target ADDEPEV3 and treatment ACEHVSEX\n",
      "Average Treatment Effect (LRS Regressor): -0.23 (-0.26, -0.20)\n",
      "Average Treatment Effect (Neural Network (MLP)): -0.23 (-0.26, -0.20)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): -0.18 (-0.20, -0.15)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): -0.01 (-0.01, -0.01)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACEDEPRS\n",
      "Average Treatment Effect (LRS Regressor): -16.47 (-17.25, -15.70)\n",
      "Average Treatment Effect (Neural Network (MLP)): -14.98 (-15.70, -14.26)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): -16.26 (-16.97, -15.55)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): -14.48 (-14.49, -14.48)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACEDRINK\n",
      "Average Treatment Effect (LRS Regressor): -8.92 (-9.61, -8.24)\n",
      "Average Treatment Effect (Neural Network (MLP)): -8.30 (-8.97, -7.63)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): -8.54 (-9.20, -7.87)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): -7.07 (-7.08, -7.07)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACEDRUGS\n",
      "Average Treatment Effect (LRS Regressor): -11.38 (-12.36, -10.39)\n",
      "Average Treatment Effect (Neural Network (MLP)): -10.57 (-11.52, -9.62)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): -12.36 (-13.28, -11.44)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): -11.92 (-11.93, -11.92)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACEPRISN\n",
      "Average Treatment Effect (LRS Regressor): -8.92 (-10.05, -7.80)\n",
      "Average Treatment Effect (Neural Network (MLP)): -7.93 (-9.01, -6.85)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): -8.86 (-9.89, -7.82)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): -8.49 (-8.50, -8.49)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACEDIVRC\n",
      "Average Treatment Effect (LRS Regressor): -5.09 (-5.79, -4.38)\n",
      "Average Treatment Effect (Neural Network (MLP)): -8.36 (-9.02, -7.69)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): -4.91 (-5.57, -4.25)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): -3.96 (-3.97, -3.96)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACEPUNCH\n",
      "Average Treatment Effect (LRS Regressor): 9.45 (7.91, 10.99)\n",
      "Average Treatment Effect (Neural Network (MLP)): 5.24 (3.72, 6.77)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): 8.84 (7.43, 10.26)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): 0.46 (0.46, 0.47)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACEHURT1\n",
      "Average Treatment Effect (LRS Regressor): 9.35 (8.13, 10.56)\n",
      "Average Treatment Effect (Neural Network (MLP)): 7.98 (6.77, 9.19)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): 9.53 (8.37, 10.69)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): 0.84 (0.83, 0.84)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACESWEAR\n",
      "Average Treatment Effect (LRS Regressor): 12.51 (11.10, 13.93)\n",
      "Average Treatment Effect (Neural Network (MLP)): 9.52 (8.12, 10.92)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): 12.10 (10.77, 13.43)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): 1.07 (1.06, 1.07)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACETOUCH\n",
      "Average Treatment Effect (LRS Regressor): 10.99 (9.49, 12.48)\n",
      "Average Treatment Effect (Neural Network (MLP)): 14.59 (13.10, 16.08)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): 10.93 (9.54, 12.33)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): 0.56 (0.55, 0.56)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACETTHEM\n",
      "Average Treatment Effect (LRS Regressor): 11.32 (9.66, 12.98)\n",
      "Average Treatment Effect (Neural Network (MLP)): 9.83 (8.17, 11.49)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): 11.56 (10.05, 13.07)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): 0.44 (0.44, 0.45)\n",
      "\n",
      "\n",
      "Performing analysis for target MENTHLTH and treatment ACEHVSEX\n",
      "Average Treatment Effect (LRS Regressor): 12.43 (10.27, 14.59)\n",
      "Average Treatment Effect (Neural Network (MLP)): 10.62 (8.46, 12.78)\n",
      "Average Treatment Effect (BaseXRegressor using XGBoost): 13.06 (11.21, 14.90)\n",
      "Average Treatment Effect (BaseRRegressor using XGBoost): 0.26 (0.25, 0.27)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Declare the feature columns\n",
    "feature_cols = ['_AGE_G', '_SEX', '_EDUCAG', '_INCOMG1']\n",
    "\n",
    "# Declare the target columns\n",
    "target_cols = ['ADDEPEV3', 'MENTHLTH']\n",
    "\n",
    "# Declare the treatment columns\n",
    "treatment_cols = ['ACEDEPRS', 'ACEDRINK', 'ACEDRUGS', 'ACEPRISN',\n",
    "       'ACEDIVRC', 'ACEPUNCH', 'ACEHURT1', 'ACESWEAR', 'ACETOUCH', 'ACETTHEM',\n",
    "       'ACEHVSEX']\n",
    "\n",
    "# Iterate over all combinations of target and treatment columns\n",
    "for target in target_cols:\n",
    "    for treatment in treatment_cols:\n",
    "        print(f\"Performing analysis for target {target} and treatment {treatment}\")\n",
    "        perform_analysis(ace_data, target, treatment, feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copilot on Interpretation:\n",
    "\n",
    "For the binary target ADDEPEV3 with treatment ACEDEPRS:\n",
    "\n",
    "The Average Treatment Effect (ATE) is a measure of the difference in mean (average) outcomes between units that received the treatment and those that did not. In this case, the ATE is the difference in the average outcome of ADDEPEV3 (whether a person has experienced a depressive episode) between those who have experienced ACEDEPRS (a form of adverse childhood experience) and those who have not.\n",
    "\n",
    "The results from the different models (LRS Regressor, Neural Network, BaseXRegressor using XGBoost, and BaseRRegressor using XGBoost) are all around 0.25 to 0.30. This suggests that, on average, experiencing ACEDEPRS increases the likelihood of having a depressive episode (ADDEPEV3) by about 25% to 30%. The numbers in parentheses are the lower and upper bounds of a 95% confidence interval for the ATE, indicating the range within which we can be 95% confident that the true ATE lies.\n",
    "\n",
    "In simpler terms: These results suggest that people who have experienced this particular adverse childhood experience are about 25% to 30% more likely to have had a depressive episode.\n",
    "\n",
    "For the continuous target MENTHLTH with treatment ACEHVSEX:\n",
    "\n",
    "The interpretation is similar, but now the ATE represents the difference in the average number of days of poor mental health (MENTHLTH) between those who have experienced ACEHVSEX (another form of adverse childhood experience) and those who have not.\n",
    "\n",
    "The results from the different models suggest that, on average, experiencing ACEHVSEX increases the number of days of poor mental health by about 10 to 13 days. The BaseRRegressor using XGBoost model seems to be an outlier with an ATE of 0.26, which might suggest some issue with the model or the data.\n",
    "\n",
    "In simpler terms: These results suggest that people who have experienced this particular adverse childhood experience have, on average, 10 to 13 more days of poor mental health."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Example with Drugs as Treatment and Mental Health as Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.]\n",
      "(59508, 4)\n",
      "(59508,)\n",
      "(59508,)\n"
     ]
    }
   ],
   "source": [
    "# filter out rows that have `nan` values in the 'ACEDRUGS' or 'MENTHLTH' columns\n",
    "ace_data = ace_data.dropna(subset=['ACEDRUGS', 'MENTHLTH'])\n",
    "\n",
    "# Filter the dataset to only include rows where the 'ACEDRUGS' column is less than 2\n",
    "ace_data = ace_data[ace_data['ACEDRUGS'] < 3] # Only two levels of treatment\n",
    "\n",
    "# Declare the treatment\n",
    "treatment = ace_data['ACEDRUGS']\n",
    "\n",
    "# Declare the target\n",
    "# y = ace_data['MENTHLTH']\n",
    "y = ace_data['ACEDEPRS']\n",
    "\n",
    "# # Subtract 1 from the treatment column\n",
    "treatment = treatment - 1 \n",
    "# TODO I need to confirm what 0 and 1 should mean for CausalML i.e. YES and NO or NO and YES\n",
    "\n",
    "print(treatment.unique())\n",
    "\n",
    "# Declare X\n",
    "X = ace_data[['_AGE_G', '_SEX', '_EDUCAG', '_INCOMG1']]\n",
    "\n",
    "# Print the shapes of X, treatment, and y\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(treatment.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propensity Score\n",
    "Propensity score, which is the probability of receiving the treatment given the observed features.\n",
    "\n",
    "In the context of causal inference, the propensity score is a balancing score: conditional on the propensity score, the distribution of observed covariates will be the same between treated and untreated subjects.\n",
    "\n",
    "To create e with non-synthetic data, you would typically use a binary classification model where the features are your covariates and the target is whether or not the subject received treatment. The predicted probability of receiving treatment is your propensity score.\n",
    "\n",
    "This code fits a logistic regression model to predict the treatment given the features, and then uses this model to compute the propensity score. Note that this is a very basic example and in practice you might need to consider more sophisticated models or methods to estimate the propensity score, depending on the complexity of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59508\n"
     ]
    }
   ],
   "source": [
    "# Calculate the propensity score (basic and prompt engineered could be wrong)\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# The propensity score\n",
    "e = model.predict_proba(X)[:, 1]\n",
    "print(len(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.38963115]), array([0.3675007]), array([0.4117616]))\n",
      "ATE estimate: 0.390\n",
      "ATE lower bound: 0.368\n",
      "ATE upper bound: 0.412\n"
     ]
    }
   ],
   "source": [
    "learner_s = LRSRegressor()\n",
    "ate_s = learner_s.estimate_ate(X=X, treatment=treatment, y=y)\n",
    "print(ate_s)\n",
    "print('ATE estimate: {:.03f}'.format(ate_s[0][0]))\n",
    "print('ATE lower bound: {:.03f}'.format(ate_s[1][0]))\n",
    "print('ATE upper bound: {:.03f}'.format(ate_s[2][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Treatment Effect (Neural Network (MLP)): 0.31 (0.29, 0.33)\n"
     ]
    }
   ],
   "source": [
    "nn = MLPTRegressor(hidden_layer_sizes=(10, 10),\n",
    "                 learning_rate_init=.1,\n",
    "                 early_stopping=True,\n",
    "                 random_state=42)\n",
    "te, lb, ub = nn.estimate_ate(X, treatment, y)\n",
    "print('Average Treatment Effect (Neural Network (MLP)): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Treatment Effect (BaseXRegressor using XGBoost): 0.36 (0.34, 0.38)\n"
     ]
    }
   ],
   "source": [
    "xl = BaseXRegressor(learner=XGBRegressor(random_state=42))\n",
    "te, lb, ub = xl.estimate_ate(X, treatment, y, e)\n",
    "print('Average Treatment Effect (BaseXRegressor using XGBoost): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Treatment Effect (BaseRRegressor using XGBoost): 0.30 (0.30, 0.30)\n"
     ]
    }
   ],
   "source": [
    "rl = BaseRRegressor(learner=XGBRegressor(random_state=42))\n",
    "te, lb, ub =  rl.estimate_ate(X=X, p=e, treatment=treatment, y=y)\n",
    "print('Average Treatment Effect (BaseRRegressor using XGBoost): {:.2f} ({:.2f}, {:.2f})'.format(te[0], lb[0], ub[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
